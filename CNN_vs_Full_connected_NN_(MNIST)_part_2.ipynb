{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZvoneST/pytorch-labs/blob/master/CNN_vs_Full_connected_NN_(MNIST)_part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef5edb03",
      "metadata": {
        "id": "ef5edb03"
      },
      "source": [
        "### Step 1: Install Torch\n",
        "- Execute the following cell which will install **torch** and **torchvision**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c19e8755",
      "metadata": {
        "id": "c19e8755"
      },
      "outputs": [],
      "source": [
        "#!pip install torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b8bc9a2",
      "metadata": {
        "id": "6b8bc9a2"
      },
      "source": [
        "### Step 2: Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fca19d9d",
      "metadata": {
        "id": "fca19d9d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb3a4ae5",
      "metadata": {
        "id": "cb3a4ae5"
      },
      "source": [
        "### Step 3: Download the CIFAR10 dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73c6e5bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73c6e5bb",
        "outputId": "3e12da68-d2e6-441b-ffd4-37e51ef8ac7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "data_path = 'downloads/'\n",
        "cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
        "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd1bd0ca",
      "metadata": {
        "id": "cd1bd0ca"
      },
      "source": [
        "### Step 4: Explore the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a18c1717",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a18c1717",
        "outputId": "650da8c3-dc49-4d65-a5b8-3e9f7e4cd42c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.cifar.CIFAR10"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "type(cifar10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5494a539",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5494a539",
        "outputId": "f6b02aee-705a-4b3a-f4b3-31da5307d979"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "len(cifar10), len(cifar10_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f74c3dc",
      "metadata": {
        "id": "6f74c3dc"
      },
      "outputs": [],
      "source": [
        "img, label = cifar10[1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65639015",
      "metadata": {
        "id": "65639015"
      },
      "source": [
        "### Step 5: Visualize the image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dbf5fa3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "3dbf5fa3",
        "outputId": "df57f684-f9c0-4f4b-8ab0-669b8ab8f8be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f471ac6bc50>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c1e704f",
      "metadata": {
        "id": "8c1e704f"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8005d75d",
      "metadata": {
        "id": "8005d75d"
      },
      "source": [
        "### Step 6: Transform images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d7c8a44",
      "metadata": {
        "id": "5d7c8a44"
      },
      "outputs": [],
      "source": [
        "tensor_cifar10 = datasets.CIFAR10(data_path, train = True, download = False, transform = transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9dac2ba",
      "metadata": {
        "id": "a9dac2ba"
      },
      "outputs": [],
      "source": [
        "imgs = torch.stack([img_t for img_t, _ in tensor_cifar10], dim = 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe65a981",
      "metadata": {
        "id": "fe65a981"
      },
      "source": [
        "### Step 7: Normalize images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f02d859",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f02d859",
        "outputId": "a7b825e1-2fb0-4d3f-e222-6074ba0549b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4914, 0.4822, 0.4465])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "imgs.view(3, -1).mean(dim = 1)   #Why is output a 3 number?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9707c57",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9707c57",
        "outputId": "83640b73-113c-4069-9ce5-d2c6c9c9d25d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2470, 0.2435, 0.2616])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "imgs.view(3, -1).std(dim = 1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5789d4b3",
      "metadata": {
        "id": "5789d4b3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d298703f",
      "metadata": {
        "id": "d298703f"
      },
      "source": [
        "### Step 8: Normalize the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "069a5ea8",
      "metadata": {
        "id": "069a5ea8"
      },
      "outputs": [],
      "source": [
        "cifar10 = datasets.CIFAR10(data_path, train = True, download = False, transform = transforms.Compose([\n",
        "                                                                                                             transforms.ToTensor(),\n",
        "                                                                                                             transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "037d04db",
      "metadata": {
        "id": "037d04db"
      },
      "outputs": [],
      "source": [
        "cifar10_val = datasets.CIFAR10(data_path, train = False, download = False, transform = transforms.Compose([\n",
        "                                                                                                             transforms.ToTensor(),\n",
        "                                                                                                             transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1ef2dcd",
      "metadata": {
        "id": "f1ef2dcd"
      },
      "source": [
        "### Step 9: Limit the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d81727b1",
      "metadata": {
        "id": "d81727b1"
      },
      "outputs": [],
      "source": [
        "label_map = {0: 0, 2: 1}\n",
        "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]\n",
        "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0, 2]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60bb3eac",
      "metadata": {
        "id": "60bb3eac"
      },
      "source": [
        "### Step 10: Create the model\n",
        "**Ex2:** Which number need to written in place of x and y? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a34ddf7",
      "metadata": {
        "id": "5a34ddf7"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(nn.Linear(32*32*3, 512), nn.Tanh(), nn.Linear(512, 2), nn.LogSoftmax(dim=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf32440f",
      "metadata": {
        "id": "cf32440f"
      },
      "source": [
        "### Step 11: Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0571922e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0571922e",
        "outputId": "84814750-ac76-4c5d-8739-1d48ecf1d1d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.438571\n",
            "Epoch: 1, Loss: 0.512907\n",
            "Epoch: 2, Loss: 0.655156\n",
            "Epoch: 3, Loss: 0.501520\n",
            "Epoch: 4, Loss: 0.272134\n",
            "Epoch: 5, Loss: 0.624478\n",
            "Epoch: 6, Loss: 0.331266\n",
            "Epoch: 7, Loss: 0.353600\n",
            "Epoch: 8, Loss: 0.135475\n",
            "Epoch: 9, Loss: 0.447378\n"
          ]
        }
      ],
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "learning_rate = 0.01\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.NLLLoss()\n",
        "n_epochs = 10\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        batch_size = imgs.shape[0]\n",
        "        outputs = model(imgs.view(batch_size, -1))\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92a127ed",
      "metadata": {
        "id": "92a127ed"
      },
      "source": [
        "### Step 12: Test the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0239d06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0239d06",
        "outputId": "16dcd22a-6b2c-4769-9f6a-6c3722e1b68f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: %f 0.8445\n"
          ]
        }
      ],
      "source": [
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                       shuffle=False)\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for imgs, labels in val_loader:\n",
        "      batch_size = imgs.shape[0]\n",
        "      outputs = model(imgs.view(batch_size, -1))\n",
        "      _, predicted = torch.max(outputs, dim=1)\n",
        "      total += labels.shape[0]\n",
        "      correct += int((predicted == labels).sum())\n",
        "print(\"Accuracy: %f\", correct / total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f167b492",
      "metadata": {
        "id": "f167b492"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99161df7",
      "metadata": {
        "id": "99161df7"
      },
      "source": [
        "### Step 13 (Optional): Improve the model\n",
        "\n",
        "\n",
        "1.   Try with CNN\n",
        "2.   ...\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37270489",
      "metadata": {
        "id": "37270489"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv3 = nn.Conv2d(20, 20, kernel_size=3)\n",
        "        self.mp = nn.MaxPool2d(2)\n",
        "        self.fc = nn.Linear(500, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        in_size = x.size(0)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        #print(x.shape)\n",
        "        x = F.relu(self.mp(self.conv2(x)))\n",
        "        x = F.relu(self.mp(self.conv3(x)))\n",
        "        \n",
        "        \n",
        "        x = x.view(in_size, -1)  # flatten the tensor\n",
        "        \n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x)\n",
        "\n",
        "\n",
        "model2 = Net()\n",
        "#model = nn.Sequential(nn.Conv2d(3, 10, kernel_size=5),nn.MaxPool2d(2) ,nn.ReLU(), nn.Conv2d(10, 20, kernel_size=5),nn.MaxPool2d(2) ,nn.ReLU(), nn.Linear(500, 2), nn.Softmax(dim=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "281083ed",
      "metadata": {
        "id": "281083ed"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "optimizer = optim.SGD(model2.parameters(), lr=0.01, momentum=0.5)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=cifar2_val,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "def train(epoch):\n",
        "    model2.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = model2(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "       # if batch_idx % 10 == 0:\n",
        "            #print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                #epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                #100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test():\n",
        "    model2.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        output = model2(data)\n",
        "        # sum up batch loss\n",
        "        test_loss += F.nll_loss(output, target, size_average=False).data\n",
        "        # get the index of the max log-probability\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BpR2wvnXV_yD"
      },
      "id": "BpR2wvnXV_yD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0f103c9c",
      "metadata": {
        "id": "0f103c9c"
      },
      "source": [
        "### Ex3: Add more filtters\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=3)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(20, 20, kernel_size=2)\n",
        "        self.mp = nn.MaxPool2d(2)\n",
        "\n",
        "        self.fc = nn.Linear(720, 2)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        in_size = x.size(0)\n",
        "\n",
        "        x = F.relu(self.conv1(x))\n",
        "\n",
        "        #print(x.shape)\n",
        "\n",
        "        x = F.relu(self.mp(self.conv2(x)))\n",
        "\n",
        "        x = F.relu(self.mp(self.conv3(x)))\n",
        "\n",
        "        #x = F.relu(self.mp(self.conv4(x)))\n",
        "\n",
        "        \n",
        "\n",
        "        #print(\"2.\", x.shape)\n",
        "\n",
        "       # x = F.relu(self.mp(self.conv3(x)))\n",
        "\n",
        "        x = x.view(in_size, -1)  # flatten the tensor\n",
        "\n",
        "        #print(\"3.\", x.shape)\n",
        "\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return F.log_softmax(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model2 = Net()"
      ],
      "metadata": {
        "id": "bYSyv_iXGHvB"
      },
      "id": "bYSyv_iXGHvB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0BxPn544fI7",
        "outputId": "51485f4e-fefc-483c-e11f-2e0c9c822f0c"
      },
      "id": "-0BxPn544fI7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6952, Accuracy: 4311/10000 (43%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ex4: Try ensamble method"
      ],
      "metadata": {
        "id": "o3sVfPs75KdP"
      },
      "id": "o3sVfPs75KdP"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MyEnsemble(nn.Module):\n",
        "    def __init__(self, modelA, modelB):\n",
        "        super(MyEnsemble, self).__init__()\n",
        "        self.modelA = modelA\n",
        "        self.modelB = modelB\n",
        "        self.classifier = nn.Linear(3072, 2)\n"
      ],
      "metadata": {
        "id": "63rcpl3h5kjD"
      },
      "id": "63rcpl3h5kjD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "89OWdIbMu-fq"
      },
      "id": "89OWdIbMu-fq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DSRGWCUOu5vU"
      },
      "id": "DSRGWCUOu5vU",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "CNN vs Full connected NN (MNIST) - part 2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}